{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b7d4ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized empty a_space_emb size:  torch.Size([1653, 8])\n",
      " 3229 / 151722\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PyKing\\Desktop\\git_pull\\RL-mid\\feature.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p_feature = torch.tensor(p_history[p_id2index[str(p_id)]], dtype=torch.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final a_space_emb size:  torch.Size([137008, 1653, 8])\n",
      "requester s1 size: torch.Size([137008, 1329])\n",
      "requester s2 size: torch.Size([137008, 1329])\n",
      "requester a size: torch.Size([137008])\n",
      "initialized empty a_space_emb size:  torch.Size([1653, 8])\n",
      "final a_space_emb size:  torch.Size([18079, 1653, 8])\n",
      "initialized empty a_space_emb size:  torch.Size([1653, 8])\n",
      "final a_space_emb size:  torch.Size([17390, 1653, 8])\n"
     ]
    }
   ],
   "source": [
    "from load_datas import Dataloader\n",
    "from feature import get_features\n",
    "# from dqn_worker import train_worker_dqn\n",
    "\n",
    "dataloader = Dataloader()\n",
    "\n",
    "train_data, valid_data, test_data = dataloader.get_datas()\n",
    "\n",
    "\n",
    "train_r_data, train_w_data = get_features(train_data, print_size=True)\n",
    "valid_r_data, valid_w_data = get_features(valid_data)\n",
    "test_r_data, test_w_data = get_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b141b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.any(torch.isnan(train_r_data['a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f26ecc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done cov\n",
      "Done e\n",
      "torch.Size([172477, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def de_dim(train_r_data, valid_r_data, test_r_data, key, dim=128):\n",
    "    S = torch.cat([train_r_data[key], valid_r_data[key], test_r_data[key]], dim=0)\n",
    "    \n",
    "    n = S.size(0)\n",
    "    S_centered = S - torch.mean(S, dim=0)\n",
    "\n",
    "    # S_centered = S_centered.to(device)\n",
    "    cov_matrix = torch.mm(S_centered.t(), S_centered) / (n - 1)\n",
    "    print(\"Done cov\")\n",
    "    e_values, e_vectors = torch.linalg.eigh(cov_matrix)\n",
    "    print(\"Done e\")\n",
    "\n",
    "    sorted_indices = torch.argsort(e_values, descending=True)\n",
    "    e_vectors = e_vectors[:, sorted_indices]\n",
    "\n",
    "    p_comp = e_vectors[:, :dim]\n",
    "    S_reduced = torch.mm(S_centered, p_comp)\n",
    "    print(S_reduced.size())\n",
    "    torch.save(S_reduced, \"data/pca_data/low_dim_%s.pt\" % key)\n",
    "\n",
    "de_dim(train_r_data, valid_r_data, test_r_data, 's1', dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c78a590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done cov\n",
      "Done e\n",
      "torch.Size([172477, 128])\n"
     ]
    }
   ],
   "source": [
    "de_dim(train_r_data, valid_r_data, test_r_data, 's2', dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55e1f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'a_space_emb'\n",
    "S = torch.cat([train_r_data[key], valid_r_data[key], test_r_data[key]], dim=0)\n",
    "torch.save(S, \"data/pca_data/low_dim_%s.pt\" % key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0eafc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'a'\n",
    "S = torch.cat([train_r_data[key], valid_r_data[key], test_r_data[key]], dim=0)\n",
    "torch.save(S, \"data/pca_data/low_dim_%s.pt\" % key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d0c29cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'r'\n",
    "S = torch.cat([torch.tensor(train_r_data[key]), torch.tensor(valid_r_data[key]), torch.tensor(test_r_data[key])], dim=0)\n",
    "S = (S - S.min()) / S.max()\n",
    "torch.save(S, \"data/pca_data/low_dim_%s.pt\" % key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041b2241",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'r'\n",
    "S = torch.cat([torch.tensor(train_w_data[key]), torch.tensor(valid_w_data[key]), torch.tensor(test_w_data[key])], dim=0)\n",
    "S = (S - S.min()) / S.max()\n",
    "torch.save(S, \"data/pca_data/low_dim_w_%s.pt\" % key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f0055ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PyKing\\AppData\\Local\\Temp\\ipykernel_14152\\470929991.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  datas[key] = torch.load(\"data/pca_data/low_dim_%s.pt\"%key)\n",
      "C:\\Users\\PyKing\\AppData\\Local\\Temp\\ipykernel_14152\\470929991.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  wr = torch.load(\"data/pca_data/low_dim_w_r.pt\")\n"
     ]
    }
   ],
   "source": [
    "# 读数据代码：\n",
    "\n",
    "import torch\n",
    "\n",
    "train_num, valid_num = 137008, 18079\n",
    "train_r_data, train_w_data, valid_r_data, valid_w_data, test_r_data, test_w_data = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "keys = ['s1', \"s2\", 'a', 'a_space_emb', 'r']\n",
    "datas = {}\n",
    "for key in keys:\n",
    "    datas[key] = torch.load(\"data/pca_data/low_dim_%s.pt\"%key)\n",
    "\n",
    "for key in keys:\n",
    "    train_r_data[key] = datas[key][:train_num]\n",
    "    valid_r_data[key] = datas[key][train_num:train_num+valid_num]\n",
    "    test_r_data[key] = datas[key][train_num+valid_num:]\n",
    "\n",
    "wr = torch.load(\"data/pca_data/low_dim_w_r.pt\")\n",
    "train_w_data['r'] = wr[:train_num]\n",
    "valid_w_data['r'] = wr[train_num:train_num+valid_num]\n",
    "test_w_data['r'] = wr[train_num+valid_num:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5c501c",
   "metadata": {},
   "source": [
    "数据维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efdd64d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train requester:\n",
      "s1 torch.Size([137008, 128])\n",
      "s2 torch.Size([137008, 128])\n",
      "a torch.Size([137008])\n",
      "a_space_emb torch.Size([137008, 1653, 8])\n",
      "r torch.Size([137008])\n",
      "\n",
      "valid requester:\n",
      "s1 torch.Size([18079, 128])\n",
      "s2 torch.Size([18079, 128])\n",
      "a torch.Size([18079])\n",
      "a_space_emb torch.Size([18079, 1653, 8])\n",
      "r torch.Size([18079])\n",
      "\n",
      "test requester:\n",
      "s1 torch.Size([17390, 128])\n",
      "s2 torch.Size([17390, 128])\n",
      "a torch.Size([17390])\n",
      "a_space_emb torch.Size([17390, 1653, 8])\n",
      "r torch.Size([17390])\n"
     ]
    }
   ],
   "source": [
    "print(\"train requester:\")\n",
    "for key in keys:\n",
    "    print(key, train_r_data[key].size())\n",
    "print(\"\\nvalid requester:\")\n",
    "for key in keys:\n",
    "    print(key, valid_r_data[key].size())\n",
    "print(\"\\ntest requester:\")\n",
    "for key in keys:\n",
    "    print(key, test_r_data[key].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afd8e956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train worker:\n",
      "r torch.Size([137008])\n",
      "valid worker:\n",
      "r torch.Size([18079])\n",
      "test worker:\n",
      "r torch.Size([17390])\n"
     ]
    }
   ],
   "source": [
    "print(\"train worker:\")\n",
    "print('r', train_w_data['r'].size())\n",
    "print(\"valid worker:\")\n",
    "print('r', valid_w_data['r'].size())\n",
    "print(\"test worker:\")\n",
    "print('r', test_w_data['r'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d9d81a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
